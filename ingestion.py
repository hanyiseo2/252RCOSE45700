import os
from langchain_community.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# OpenAI API í‚¤ í™•ì¸
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")

print("ğŸ“¥ ë°ì´í„° ë¡œë”© ì‹œì‘...")

urls = [
    "https://docs.aws.amazon.com/wellarchitected/latest/responsible-ai-lens/responsible-ai-lens.html",
    "https://docs.aws.amazon.com/wellarchitected/latest/generative-ai-lens/generative-ai-lens.html",
    "https://docs.aws.amazon.com/wellarchitected/latest/machine-learning-lens/machine-learning-lens.html"
]

# ì›¹í˜ì´ì§€ ë¡œë“œ
loader = WebBaseLoader(urls)
documents = loader.load()
print(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

# í…ìŠ¤íŠ¸ ì²­í‚¹
print("âœ‚ï¸ ë¬¸ì„œ ì²­í‚¹ ì¤‘...")
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200
)
chunks = text_splitter.split_documents(documents)
print(f"âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")

# ì„ë² ë”© ìƒì„± ë° ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•
print("ğŸ”¢ ì„ë² ë”© ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(chunks, embeddings)
print("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")

# ë¡œì»¬ì— ì €ì¥
print("ğŸ’¾ ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì¤‘...")
vectorstore.save_local("vectorstore")
print("âœ… ì €ì¥ ì™„ë£Œ: ./vectorstore/")

print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
print(f"ì´ {len(documents)}ê°œ ë¬¸ì„œ, {len(chunks)}ê°œ ì²­í¬ ì²˜ë¦¬ë¨")